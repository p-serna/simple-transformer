{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3d89d7",
   "metadata": {},
   "source": [
    "# Translating dataset duplicated Qs in Quora\n",
    "\n",
    "Following https://huggingface.co/course/chapter3/3?fw=tf\n",
    "https://huggingface.co/tuner007/pegasus_paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba038c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ae0990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset quora (/home/pablo/.cache/huggingface/datasets/quora/default/0.0.0/36ba4cd42107f051a158016f1bea6ae3f4685c5df843529108a54e42d86c1e04)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a52809dfa784514ba6e106613586edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"quora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769af4c",
   "metadata": {},
   "source": [
    "## Duplicated questions\n",
    "We check first the duplicated questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9170dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'questions': {'id': [11, 12], 'text': ['Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?', \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\"]}, 'is_duplicate': True}\n"
     ]
    }
   ],
   "source": [
    "for d in dataset[\"train\"]:\n",
    "    if d[\"is_duplicate\"]:\n",
    "        print(d)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3105b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [d for d in dataset[\"train\"] if d[\"is_duplicate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4221523e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149263"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43142fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': {'id': [37, 38],\n",
       "  'text': ['Why are so many Quora users posting questions that are readily answered on Google?',\n",
       "   'Why do people ask Quora questions which can be answered easily by Google?']},\n",
       " 'is_duplicate': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90033cb2",
   "metadata": {},
   "source": [
    "## Loading the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e7bed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3529673073ce4e95b89f368a4a303b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7831da603bc4d7a82d043509f126282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de64be7a1840492aa88100385e6e8027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/783k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaca7d019d549d18b16fdf9aadeb6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/807k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb33110fb4b481687c77546667586a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0a68deb72a44c595a09df601e4f76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/298M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece02d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cpu\"#'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd631028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d189c4",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0509ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿Quién es Iban Ríos?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_beams = 10\n",
    "num_return_sequences = 1\n",
    "context = \"who is Iban Rios?\"\n",
    "get_response(context,num_return_sequences,num_beams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e29bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a993dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where can you find out what needs to be improved if your question was marked for needing revision?', 'Is there a way on Quora to ask why a specific question was marked as needs improvement?']\n",
      "['¿Dónde puede usted averiguar lo que necesita ser mejorado si su pregunta fue marcada para la necesidad de revisión?'] ['¿Hay alguna manera en Quora de preguntar por qué una pregunta específica fue marcada como mejora de las necesidades?']\n"
     ]
    }
   ],
   "source": [
    "dt = random.choice(ds)\n",
    "print(dt[\"questions\"][\"text\"])\n",
    "context = dt[\"questions\"][\"text\"][0]\n",
    "r1 = get_response(context,num_return_sequences,num_beams)\n",
    "context = dt[\"questions\"][\"text\"][1]\n",
    "r2 = get_response(context,num_return_sequences,num_beams)\n",
    "print(r1,r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3d047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
